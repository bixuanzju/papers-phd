\section{Implementation}\label{sec:implementation}

We implemented\footnote{\name code repository: \url{https://github.com/hkuplg/fcore}} a compiler for \name based on the
representation and type-directed translation we described in
Sections~\ref{sec:fcore} and \ref{sec:tce}.  We wrote the compiler
in Haskell. This section overviews additional information about the
implementation. Our actual implementation first translates System F
to an equivalent intermediate form with multi-binders (Closure F),
from which it generates Java code.

\subsection{Syntax Extensions and Java Interoperability}
The implemented \name and Closure F extend the basic 
System F with other constructs. These include primitive
operations, types and literals, let bindings, conditional expressions,
tuples, and fixpoints. We also have different frontends, 
which extend \name with convenient language constructs that helped us in development.
We wrote our benchmark programs in one 
of these frontends. 
%\name and Closure F intermediate languages' value and type
%expressions with several useful constructs. 

We also added constructs for a basic interoperability mechanism with
Java and the JVM: creating instances of classes, calling methods,
accessing fields, and executing blocks of statements.  We type-check these constructs
using an ``oracle''.  In the implementation, the type-checker sends
queries about Java constructs to a server with a set classpath and the
server answers these queries using the Reflection
API. One advantage of this design is that it allows
us to target different Java-based platforms. Apart from supporting the
JVM, we can support the Android platform. The Android platform
uses a different set of libraries from the JVM SDK. 

Besides benchmark programs, we have a number of other programs written 
in \Name. These programs include functional programs for 
drawing fractals (such as the Mandelbrot set, the Burning Ship, or the
Sierpinski Triangle) which helped us to test the Java interoperability.
We also have a test suite with unit tests of the \name compiler.

%\subsection{Multi-argument Closure Optimization}

\subsection{Thread Safety and Delayed Memory Allocation}

System F is not a concurrent calculus and the presented technique
focuses on sequential functional-style code compilation. Nevertheless,
JVM is inherently a concurrent platform and the use of mutable fields
may seem to prevent thread safety. This would be a major drawback of
IFOs, because, for instance, the generated code could not be safely
used from multi-threading Java applications.

Before addressing the problem, we describe what multi-threading 
scenarios we are concerned about. We consider multi-threading Java programs, in which a programmer imports
some code generated by the compiler. According to the formalization of \Name, the programmer
gets a \lstinline{Function} instance. This instance may be shared
by multiple threads in the application program, thus results of
function invocations may be incorrect due to the interleaving of
these threads.

This, however, can be easily fixed: we enforce a separate
instance for each thread by allocating objects at their call sites
rather than at their definition sites. This is reflected in our actual
implementation: each \emph{FC} class definition is followed by a wrapping \lstinline{Thunk}
instance. Here, we briefly illustrate the idea.

Suppose we compiled the following \emph{increment} function:

\vspace{5pt}
$inc \equiv (\lambda x : Int)  .~x+1$
\vspace{5pt}

\noindent into Java code:

\begin{lstlisting}
class Inc extends Function
{
  Function x2 = this;
  public void apply ()
  {
    final Integer x3 = (Integer) x2.arg;
    final Integer x4 = x3 + 1;
    res = x4;
  }
}
Thunk inc = () -> new Inc();
\end{lstlisting}

\noindent Note that on the last line, we create a \lstinline{Thunk}
instance instead of \lstinline{Function inc = new Inc()}. A \lstinline{Thunk} is
simply a Java functional interface with a single abstract method:

\begin{lstlisting}
public interface Thunk {
  public Function compute();
}
\end{lstlisting}

\noindent Now a programmer can make a thread-safe call to, for
instance, \lstinline{inc(inc(0))} as follows:

\begin{lstlisting}
Function inc1 = inc.compute();
inc1.arg = 0;
inc1.apply();
Function inc2 = inc.compute();
inc2.arg = inc1.res;
inc2.apply();
\end{lstlisting}

\noindent because \lstinline{inc1} and \lstinline{inc2} are two
different instances of the same \lstinline{Inc} class. With the
\lstinline{Thunk} interface, we can wrap the code of object allocation
inside the \lstinline{compute} method in order to delay memory allocation.
Therefore, in a multi-threading scenario, even if a
\lstinline{Thunk} instance is shared by multiple threads, each
invocation of \lstinline{compute} will result in a separate object instance.
This makes different function invocations reside
in different memory spaces without interfering with each other.

The \lstinline{Thunk} interface also works with higher-order
functions. Consider the following example:

\vspace{5pt}
$twice \equiv (\lambda f : Int \rightarrow Int) .~(\lambda x : Int) .~f~(f~x)$
\vspace{5pt}

\noindent Here \emph{twice} takes another function as an input. In the
exported Java code, a programmer is provided with a Java interface:

\begin{lstlisting}
interface Twice {
  default int twice (Thunk f, int x) {
    Function fun1 = f.compute();
    fun1.arg = (Integer) x;
    fun1.apply();
    Integer res1 = (Integer) fun1.res;
    Function fun2 = f.compute();
    fun2.arg = (Integer) res1;
    fun2.apply();
    Integer res2 = (Integer) fun2.res;
    return res2;
  }
}
\end{lstlisting}

\noindent If the programmer wants to call, for instance,
\lstinline{twice inc}, he/she is forced to pass a \lstinline{Thunk}
instance of \lstinline{inc} to the \lstinline{twice} method as an
argument. This ensures that each call with the function argument
sees a new instance of \lstinline{Function} class.

The \lstinline{Thunk} interface works well with System F binders
and \emph{let} expressions. At the moment, we are implementing a
modified version to work with TCE. Because in the TCE-augmented
translation, there would be an additional race condition due to the
static \lstinline{Next} field. Again, we only need a small
modification: the \lstinline{Next} field should not be static and
\lstinline{Next} must have a local instance in each thread. Function
applications would be done via this local instance of \lstinline{Next}
rather than the class. We leave a full implementation for future work.


% \begin{tabular}[t]{l l}
% \begin{lstlisting}

% //thread unsafe
% ...
% Function constant =
%   new Constant();
% ...
% Thread thread1 =
%   new Thread() {
%     public void run() {
%       constant.arg = 3;
%       constant.apply();
%       ...
%     }
%   };

% Thread thread2 =
%   new Thread() {
%     public void run() {
%       constant.arg = 5;
%       constant.apply();
%       ...
%     }
%   };
% ...
% \end{lstlisting}&
% \hspace{20pt}\begin{lstlisting}
% //thread safe
% ...
% // return a thunk instance
% Thunk tconstant =
%   () -> new Constant();
% ...
% Thread thread1 =
%   new Thread() {
%     public void run() {
%       Function constant =
%         tconstant.compute();
%       constant.arg = 3;
%       constant.apply();
%       ...
%     }
%   };

% Thread thread2 =
%   new Thread() {
%     public void run() {
%       Function constant =
%         tconstant.compute();
%       constant.arg = 5;
%       constant.apply();
%       ...
%     }
%   };
% ...
% \end{lstlisting}
% \end{tabular}

\subsection{Additional Optimizations}

Our compiler also performs standard optimizations that are not
accounted by the basic translations in Sections~\ref{sec:fcore} and
\ref{sec:tce}. It uses Java's inner classes to enforce lexical scoping
of generated variables. This nesting optimization avoids the initialization overhead
of passing the scoped variables through constructors of top level classes.
 For unboxing, different \lstinline{Function} classes exist
with specialized primitive fields. The translation chooses among them
and generates variables with primitive types when possible. The
compiler inlines expressions of let bindings, value abstractions, and
fixpoints; and partially evaluates value applications, conditionals,
and primitive type operations.

An important optimization that our compiler also does is
multi-argument function optimization. This kind of optimization is
standard in FP~\cite{marlow06making} and provides a major boost in
time and memory performance. The straightforward
translation described in the previous section has one drawback when
translating multi-argument functions: for each single value
application, we generate a function object that requires an apply call
to execute the body. Using the additional information that Closure F
has about multi-argument binders, our compiler creates a single
multi-argument function, instead of multiple single argument
functions. 

\begin{comment}
The idea employed in our implementation is similar 
to the alternative encoding of curried functions briefly presented 
in Section~\ref{subsec:ifos}.
\end{comment}

%In
% functional programming, we encounter different common scenarios, such
% as partial applied or higher-order functions, when this approach can
% become a major performance penalty. For this reason, we perform one
% optimization for these cases.  In this optimization, we augment the
% translation in two ways: we eliminate apply calls in partial
% applications and move the code blocks from apply methods to
% initialization blocks in the corresponding Closure objects. In order
% to do these two steps, we need to be able to detect partial
% applications.  Luckily, we can simply see this in types of our
% representation. When translating $E1~E2$, we have the following
% options for the E1's type $\Delta$ environment:
%
%\begin{enumerate}
%  \item $\forall \alpha.\Delta$: we continue checking next binders of $\Delta$.
%  \item $\forall (x: T).\Delta$: we know this is a partial application, hence we do not generate an apply call and move its body to the initialization block.
%  \item $\forall (x: T).\epsilon$: we know this is a full application, hence we generate code as usual.
%\end{enumerate}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../Main"
%%% End:
